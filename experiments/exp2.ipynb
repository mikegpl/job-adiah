{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to build sklearn-like pipeline for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd         \n",
    "import os.path\n",
    "\n",
    "N_JOBS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path=\"../data/csv/all.csv\"):\n",
    "    dataframe = pd.read_csv(path, index_col=0)\n",
    "    return dataframe.loc[~dataframe[\"execTimeMs\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(dataframe):\n",
    "    output = dataframe.dropna(axis=\"columns\")\n",
    "    targets = output[\"execTimeMs\"]\n",
    "    dropped = output[[\"command\", \"execTimeMs\", \"jobId\", \"ctime_mean\", \"ctime_max\", \"ctime_sum\", \"read_sum\",\"write_sum\",\"readSyscalls_sum\",\"writeSyscalls_sum\",\"readReal_sum\",\"writeReal_sum\",\"writeCancelled_sum\",\"rxBytes_sum\",\"rxPackets_sum\",\"rxErrors_sum\",\"rxDrop_sum\",\"rxFifo_sum\",\"rxFrame_sum\",\"rxCompressed_sum\",\"rxMulticast_sum\",\"txBytes_sum\",\"txPackets_sum\",\"txErrors_sum\",\"txDrop_sum\",\"txFifo_sum\",\"txColls_sum\",\"txCarrier_sum\",\"txCompressed_sum\",\"cpu_mean\",\"cpu_max\",\"memory_mean\",\"memory_max\"]]\n",
    "    features = output.drop(dropped.columns, axis=1)\n",
    "    return features, targets, dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets, dropped = prepare_dataframe(load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workflowName          object\n",
       "size                 float64\n",
       "executable            object\n",
       "args                  object\n",
       "inputs                object\n",
       "outputs               object\n",
       "name                  object\n",
       "cpu.manufacturer      object\n",
       "cpu.brand             object\n",
       "cpu.speed            float64\n",
       "cpu.cores              int64\n",
       "cpu.physicalCores      int64\n",
       "cpu.processors         int64\n",
       "mem.total              int64\n",
       "mem.free               int64\n",
       "mem.used               int64\n",
       "mem.active             int64\n",
       "mem.available          int64\n",
       "mem.buffers            int64\n",
       "mem.cached             int64\n",
       "mem.slab               int64\n",
       "mem.buffcache          int64\n",
       "mem.swaptotal          int64\n",
       "mem.swapused           int64\n",
       "mem.swapfree           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector as selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_list(series):\n",
    "    def vectorize(list_string):\n",
    "        return len(eval(list_string))\n",
    "    return np.vectorize(vectorize)(series)\n",
    "\n",
    "def ListTransformer():\n",
    "    return FunctionTransformer(func=vectorize_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_transformer = Pipeline(steps=[(\"list\", ListTransformer()), (\"scaler\", StandardScaler())])\n",
    "list_features = list(['args', 'inputs', 'outputs'])\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "numerical_features = list(features.select_dtypes(include=\"number\").columns)\n",
    "\n",
    "categorical_transformer = OneHotEncoder(sparse=False, handle_unknown = \"ignore\")\n",
    "categorical_features = list(set(features.select_dtypes(include=\"object\").columns) ^ set(list_features))\n",
    "\n",
    "def make_classifying_preprocessor(additional_features=[\"read_sum\", \"write_sum\", \"cpu_mean\", \"memory_max\"]):\n",
    "    external_features = categorical_features + additional_features\n",
    "    return ColumnTransformer(\n",
    "            transformers=[('lists', list_transformer, list_features), \n",
    "                          ('num', numerical_transformer, numerical_features),\n",
    "                          ('cat', categorical_transformer, external_features)])\n",
    "\n",
    "def make_regression_preprocessor(additional_features=[\"read_sum\", \"write_sum\", \"cpu_mean\", \"memory_max\"]):\n",
    "    external_features = numerical_features + additional_features\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('lists', list_transformer, list_features),            \n",
    "            ('num', numerical_transformer, external_features),  \n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "preprocessor = make_classifying_preprocessor(additional_features=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import percentileofscore\n",
    "import math\n",
    "\n",
    "def calculate_quantile_rank(labels, label):\n",
    "    return percentileofscore(labels, label) / 100\n",
    "\n",
    "def calculate_utilization_class(labels, label):\n",
    "    def label_for_rank(rank):\n",
    "        if rank > 0.75:\n",
    "            return 'very high'\n",
    "        elif rank > 0.5:\n",
    "            return 'high'\n",
    "        elif rank > 0.25:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'low'\n",
    "    return label_for_rank(calculate_quantile_rank(labels, label))\n",
    "\n",
    "def calculate_utilization_bucket(labels, label, num_buckets):\n",
    "    bucket_size = 1.0 / num_buckets\n",
    "    def bucket_for_rank(rank):\n",
    "        return str(math.floor(rank / bucket_size))\n",
    "    return bucket_for_rank(calculate_quantile_rank(labels, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline composition (with PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.linear_model import Lasso, SGDRegressor, ElasticNet, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_steps = [('pca', PCA(random_state=42))]\n",
    "dummy_pipeline = Pipeline(steps=base_steps +[('dummy', DummyRegressor())])\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_param_grid = {\n",
    "    'pca__n_components': np.arange(1, 50, 3),    \n",
    "}\n",
    "knn_param_grid = {\n",
    "    'knn__n_neighbors': np.arange(1, 30, 3),\n",
    "}\n",
    "regressor = ('knn', KNeighborsRegressor())\n",
    "full_pipeline = Pipeline(steps= base_steps + [regressor])\n",
    "grid_search = HalvingGridSearchCV(full_pipeline, {**knn_param_grid, **pca_param_grid}, cv=2, verbose=2, scoring=\"r2\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from loky import get_reusable_executor\n",
    "\n",
    "def rate_regressor(X_train, y_train, X_test, y_test, regressor, regressor_params, verbose=10, aggressive_elimination=True, steps=base_steps):\n",
    "    print(f\"Rating {regressor}\")\n",
    "    full_pipeline = Pipeline(steps= base_steps + [regressor])\n",
    "    vector_length = X_train.shape[1]\n",
    "    pca_param_grid = {'pca__n_components': np.arange(1, vector_length, 1),}\n",
    "    grid_search = HalvingGridSearchCV(full_pipeline, {**pca_param_grid, **regressor_params}, cv=2, verbose=verbose, scoring=\"r2\", n_jobs=N_JOBS)\n",
    "    print(\"Evaluating grid search\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # scores\n",
    "    print(\"Predicting on test set\")\n",
    "    prediction = grid_search.best_estimator_.predict(X_test)\n",
    "    \n",
    "    print(\"Calculating scores\")\n",
    "    executor = get_reusable_executor(max_workers=3, timeout=5)\n",
    "    \n",
    "    scores = [lambda true, pred: r2_score(true, pred), lambda true, pred: mean_absolute_error(true, pred), lambda true, pred: mean_absolute_percentage_error(true, pred)]\n",
    "    results = executor.map(lambda fun: fun(y_test, prediction), scores)\n",
    "    print(\"Calculated scores on test set\")\n",
    "    r2, mae, mape = list(results)\n",
    "    adjusted_r2 = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "    return {\"r2\": r2, \"adjusted_r2\": adjusted_r2, \"mae\": mae, \"mape\": mape,\"best_score\": grid_search.best_score_, \"params\": grid_search.best_params_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "def rate_classifier(X_train, y_train, X_test, y_test, classifier, classifier_params, verbose=10, aggressive_elimination=True, steps=base_steps):\n",
    "    print(f\"Rating {classifier}\")\n",
    "    full_pipeline = Pipeline(steps= base_steps + [classifier])\n",
    "    vector_length = X_train.shape[1]\n",
    "    pca_param_grid = {'pca__n_components': np.arange(1, vector_length, 1),}\n",
    "    grid_search = HalvingGridSearchCV(full_pipeline, {**pca_param_grid, **classifier_params}, cv=2, verbose=verbose, scoring=\"accuracy\", n_jobs=N_JOBS)\n",
    "    print(\"Evaluating grid search\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # scores\n",
    "    print(\"Predicting on test set\")\n",
    "    prediction = grid_search.best_estimator_.predict(X_test)\n",
    "    \n",
    "    print(\"Calculating scores\")\n",
    "    executor = get_reusable_executor(max_workers=5, timeout=5)\n",
    "    \n",
    "    scores = [\n",
    "        lambda true, pred: f1_score(true, pred, average=\"micro\"),\n",
    "        lambda true, pred: f1_score(true, pred, average=\"macro\"),\n",
    "        lambda true, pred: accuracy_score(true, pred), \n",
    "        lambda true, pred: balanced_accuracy_score(true, pred)\n",
    "    ]\n",
    "    results = executor.map(lambda fun: fun(y_test, prediction), scores)\n",
    "    print(\"Calculated scores on test set\")\n",
    "    micro, macro, accuracy, balanced_accuracy = list(results)\n",
    "    return {\"f1_micro\": micro, \"f1_macro\": macro, \"accuracy\": accuracy, \"balanced_accuracy\": balanced_accuracy, \"params\": grid_search.best_params_}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here go regressor params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = (\"knn\", KNeighborsRegressor())\n",
    "knn_params = {'knn__n_neighbors': np.arange(1, 30, 1)}\n",
    "\n",
    "dtr = (\"dtr\", DecisionTreeRegressor(random_state=5))\n",
    "dtr_params = {\"dtr__criterion\": [\"mse\", \"friedman_mse\", \"mae\", \"poisson\"]}\n",
    "\n",
    "lasso = (\"lasso\", Lasso(random_state=5))\n",
    "lasso_params = {\"lasso__alpha\": np.arange(0.01, 1, 0.05)}\n",
    "\n",
    "en = (\"elasticnet\", ElasticNet(random_state=5))\n",
    "en_params = {\"elasticnet__alpha\": np.arange(0.01, 1, 0.05), \"elasticnet__l1_ratio\": np.arange(0, 1, 0.1)}\n",
    "\n",
    "svr = (\"svr\", SGDRegressor())\n",
    "svr_params = {\"svr__loss\": [\"squared_loss\", \"huber\", \"epsilon_insensitive\"], \"svr__penalty\": ['l2', 'l1', 'elasticnet'],\n",
    "             \"svr__alpha\": np.arange(0.0001, 0.2, 0.01), \"svr__max_iter\": [10000]}\n",
    "\n",
    "rf = (\"rf\", RandomForestRegressor())\n",
    "rf_params = {\"rf__n_estimators\": np.arange(5, 100, 5), \"rf__criterion\": [\"mae\", \"mse\"], \"rf__max_features\": [\"auto\", \"sqrt\", \"log2\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here go classifier params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = (\"knn\", KNeighborsClassifier())\n",
    "knn_clf_params = {'knn__n_neighbors': np.arange(1, 30, 1)}\n",
    "\n",
    "dtr_classifier = (\"dtr\", DecisionTreeClassifier(random_state=5))\n",
    "dtr_clf_params = {\"dtr__criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "mlp_classifier = (\"mlp\", MLPClassifier())\n",
    "mlp_clf_params = {\"mlp__hidden_layer_sizes\": np.arange(1,200, 10),          \n",
    "                  \"mlp__activation\": [\"logistic\", \"tanh\", \"relu\"],         \n",
    "                  \"mlp__activation\": [\"logistic\"],         \n",
    "#                   \"mlp__alpha\": np.arange(0.01, 0.1, 0.01)\n",
    "                 }\n",
    "\n",
    "svc = (\"svc\", SVC(random_state=5))\n",
    "svc_clf_params = {\n",
    "    \"svc__C\": np.arange(0.1, 1, 0.1), \n",
    "    \"svc__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"svc__degree\": np.arange(3, 10, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(dataframe):\n",
    "    jobs_below_1200ms = dataframe.loc[dataframe[\"execTimeMs\"] < 1200]\n",
    "    jobs_between_2000ms_25000ms = dataframe.loc[dataframe[\"execTimeMs\"].between(2000, 25000)]\n",
    "    jobs_count = dataframe[\"name\"].value_counts()\n",
    "    jobs_most_occuring = dataframe.loc[dataframe[\"name\"].isin(jobs_count[jobs_count > 3000].index.values)]\n",
    "    jobs_mDiffFit = dataframe.loc[dataframe[\"name\"] == \"mDiffFit\"]\n",
    "    jobs_haplotype = dataframe.loc[dataframe[\"name\"] == \"haplotype_caller\"]\n",
    "    jobs_mShrink = dataframe.loc[dataframe[\"name\"] == \"mShrink\"]\n",
    "    return jobs_below_1200ms, jobs_between_2000ms_25000ms, jobs_most_occuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = make_datasets(load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_for_jobs = [pd.DataFrame(y) for x, y in load_data().groupby('name', as_index=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_data(features, targets, regressors, verbose=10, pipeline_steps=base_steps):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, random_state=0)\n",
    "    df = pd.DataFrame(columns=[\"name\", \"pca\", \"adjusted_r2\",\"r2\", \"mae\", \"mape\", \"best_score\", \"params\"])\n",
    "    for (regressor, params) in regressors:\n",
    "        result = rate_regressor(X_train, y_train, X_test, y_test, regressor, params, verbose, pipeline_steps)\n",
    "        df = df.append({\"name\": regressor[0], **result, \"pca\": result[\"params\"][\"pca__n_components\"]}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_classifiers_for_data(features, targets, classifiers, verbose=10, pipeline_steps=base_steps):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, random_state=0)\n",
    "    df = pd.DataFrame(columns=[\"name\", \"pca\", \"accuracy\",\"balanced_accuracy\", \"f1_micro\", \"f1_macro\", \"params\"])\n",
    "    for (classifier, params) in classifiers:\n",
    "        result = rate_classifier(X_train, y_train, X_test, y_test, classifier, params, verbose, pipeline_steps)\n",
    "        df = df.append({\"name\": classifier[0], **result, \"pca\": result[\"params\"][\"pca__n_components\"]}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_dataset(dataframe, regressors, verbose=2):\n",
    "    print(f\"Rating dataset of len {len(dataframe)}\")\n",
    "    features, targets, _ = prepare_dataframe(dataframe[:10000])\n",
    "    features = preprocessor.fit_transform(features)\n",
    "    rate_data(features, targets, regressors, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_regressors = [\n",
    "    (knn, knn_params),\n",
    "#     (dtr, dtr_params),\n",
    "    (lasso, lasso_params),\n",
    "    (en, en_params),\n",
    "    (svr, svr_params),\n",
    "]\n",
    "\n",
    "basic_classifiers = [\n",
    "    (knn_classifier, knn_clf_params),\n",
    "#     (dtr_classifier, dtr_clf_params),\n",
    "    (mlp_classifier, mlp_clf_params),\n",
    "    (svc, svc_clf_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_experiment():\n",
    "    print(\"Rating jobs datasets\")\n",
    "    for dataset in dfs_for_jobs:\n",
    "        print(dataset.iloc[0][\"name\"])\n",
    "        rate_dataset(dataset, basic_regressors)\n",
    "\n",
    "    print(\"Rating common datasets\")\n",
    "    for dataset in datasets:\n",
    "        rate_dataset(dataset, basic_regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rate_dataset(dfs_for_jobs[8], verbose=0)\n",
    "# rate_dataset(dfs_for_jobs[1], basic_regressors, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperyment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cel\n",
    "\n",
    "Dowiedzieć się jakich regresorów i klasyfikatorów używać do przewidywania poziomów zasobów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane\n",
    "krótsze niż 1200ms, 2k-25k ms, częstsze niż 3000, wszystkie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_datasets = exp1_datasets\n",
    "\n",
    "def get_pipeline_data_for_resource_buckets(data, resource, num_buckets=4):\n",
    "    \"\"\"\n",
    "    Labels are resource utilization bucket indices.\n",
    "    \"\"\"\n",
    "    features, labels, dropped = prepare_dataframe(data)\n",
    "    labels = dropped[resource].map(lambda value: calculate_utilization_bucket(dropped[resource], value, num_buckets)).to_frame()\n",
    "    features = make_classifying_preprocessor(additional_features=[]).fit_transform(features)\n",
    "    return features, labels\n",
    "\n",
    "def get_pipeline_data_for_continuous_score(data, resource):\n",
    "    \"\"\"\n",
    "    Labels are quantile ranks of resource utilization\n",
    "    \"\"\"\n",
    "    features, labels, dropped = prepare_dataframe(data)\n",
    "    labels = dropped[resource].map(lambda value: calculate_quantile_rank(dropped[resource], value)).to_frame()\n",
    "    features = make_classifying_preprocessor(additional_features=[]).fit_transform(features)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przebieg\n",
    "\n",
    "Znajdujemy najlepszy regresor dla każdego typu zasobów \n",
    "\n",
    "Znajdujemy najlepszy klasyfikator dla każdego typu zasobów przy 8 kubełkach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment2a():\n",
    "    exp2_resources = [\"read_sum\", \"write_sum\", \"cpu_mean\", \"cpu_max\", \"memory_mean\", \"memory_max\"]\n",
    "    full_df = pd.DataFrame(columns=[\"dataset\", \"resource\", \"pipeline\", \"name\", \"pca\", \"adjusted_r2\",\"r2\", \"mae\", \"mape\", \"best_score\", \"params\"])\n",
    "    \n",
    "    for name, dataset in exp2_datasets.items():\n",
    "        def run_regressor_pipeline(pipeline_name, features, targets):\n",
    "            pipeline_df = rate_data(features, targets, basic_regressors, verbose=0)\n",
    "            pipeline_df[\"pipeline\"] = pipeline_name\n",
    "            return pipeline_df\n",
    "        \n",
    "        print(f\"\\t\\tEvaluating dataset {name} of length {len(dataset)}\")\n",
    "        for resource in exp2_resources:\n",
    "            print(f\"\\tEvaluating resource {resource}\")\n",
    "\n",
    "            dataset_df = pd.concat([\n",
    "                run_regressor_pipeline(f\"continuous\", *get_pipeline_data_for_continuous_score(dataset, resource)),\n",
    "            ])\n",
    "            dataset_df[\"dataset\"] = name\n",
    "            dataset_df[\"resource\"] = resource\n",
    "            full_df = full_df.append(dataset_df)\n",
    "    return full_df\n",
    "\n",
    "def run_experiment2b():\n",
    "    exp2_resources = [\"read_sum\", \"write_sum\", \"cpu_mean\", \"cpu_max\", \"memory_mean\", \"memory_max\"]\n",
    "    full_df = pd.DataFrame(columns=[\"dataset\", \"resource\", \"pipeline\", \"name\", \"pca\",  \"accuracy\",\"balanced_accuracy\", \"f1_micro\", \"f1_macro\", \"params\"])\n",
    "    \n",
    "    for name, dataset in exp2_datasets.items():\n",
    "        def run_classifier_pipeline(pipeline_name, features, targets):\n",
    "            pipeline_df = rate_classifiers_for_data(features, targets, basic_classifiers, verbose=0)\n",
    "            pipeline_df[\"pipeline\"] = pipeline_name\n",
    "            return pipeline_df\n",
    "        \n",
    "        print(f\"\\t\\tEvaluating dataset {name} of length {len(dataset)}\")\n",
    "        for resource in exp2_resources:\n",
    "            print(f\"\\tEvaluating resource {resource}\")\n",
    "\n",
    "            dataset_df = pd.concat([\n",
    "                run_classifier_pipeline(f\"classifier_10\", *get_pipeline_data_for_resource_buckets(dataset, resource, 10)),\n",
    "            ])\n",
    "            dataset_df[\"dataset\"] = name\n",
    "            dataset_df[\"resource\"] = resource\n",
    "            full_df = full_df.append(dataset_df)\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"data/exp2a.csv\"):\n",
    "    print(\"Running experiment 2a\")\n",
    "    exp2a_df = run_experiment2a()\n",
    "    exp2a_df.to_csv(\"data/exp2a.csv\")\n",
    "else:\n",
    "    exp2a_df = pd.read_csv(\"data/exp2a.csv\").round(2).reset_index().drop(columns=['Unnamed: 0', 'index'])\n",
    "\n",
    "if not os.path.isfile(\"data/exp2b.csv\"):\n",
    "    print(\"Running experiment 2b\")\n",
    "    exp2b_df = run_experiment2b()\n",
    "    exp2b_df.to_csv(\"data/exp2b.csv\")\n",
    "else:\n",
    "    exp2b_df = pd.read_csv(\"data/exp2b.csv\").round(2).reset_index().drop(columns=['Unnamed: 0', 'index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uwaga - osobny ran dla decision tree regressorów/klasyfikatorów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Output eksperymentu\n",
    "Regresory/klasyfikatory i ich parametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>resource</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>name</th>\n",
       "      <th>pca</th>\n",
       "      <th>adjusted_r2</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>best_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Between2KmsAnd25Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>knn</td>\n",
       "      <td>60</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'knn__n_neighbors': 4, 'pca__n_components': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Between2KmsAnd25Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>57</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Between2KmsAnd25Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>svr</td>\n",
       "      <td>33</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'pca__n_components': 33, 'svr__alpha': 0.0101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>All</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>65</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.73</td>\n",
       "      <td>{'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ExecutedMoreThan3Ktimes</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>knn</td>\n",
       "      <td>13</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.72</td>\n",
       "      <td>{'knn__n_neighbors': 13, 'pca__n_components': 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>All</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>knn</td>\n",
       "      <td>26</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.73</td>\n",
       "      <td>{'knn__n_neighbors': 6, 'pca__n_components': 26}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>All</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>svr</td>\n",
       "      <td>36</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.73</td>\n",
       "      <td>{'pca__n_components': 36, 'svr__alpha': 0.0001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Between2KmsAnd25Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>lasso</td>\n",
       "      <td>42</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.71</td>\n",
       "      <td>{'lasso__alpha': 0.01, 'pca__n_components': 42}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ExecutedMoreThan3Ktimes</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>40</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.71</td>\n",
       "      <td>{'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ExecutedMoreThan3Ktimes</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>svr</td>\n",
       "      <td>19</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.70</td>\n",
       "      <td>{'pca__n_components': 19, 'svr__alpha': 0.1201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>All</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>lasso</td>\n",
       "      <td>22</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.68</td>\n",
       "      <td>{'lasso__alpha': 0.01, 'pca__n_components': 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ExecutedMoreThan3Ktimes</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>lasso</td>\n",
       "      <td>29</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>{'lasso__alpha': 0.01, 'pca__n_components': 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ShorterThan1.2Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>knn</td>\n",
       "      <td>10</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.55</td>\n",
       "      <td>{'knn__n_neighbors': 10, 'pca__n_components': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ShorterThan1.2Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.55</td>\n",
       "      <td>{'elasticnet__alpha': 0.060000000000000005, 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ShorterThan1.2Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>svr</td>\n",
       "      <td>26</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>{'pca__n_components': 26, 'svr__alpha': 0.0901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ShorterThan1.2Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>continuous</td>\n",
       "      <td>lasso</td>\n",
       "      <td>17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>{'lasso__alpha': 0.01, 'pca__n_components': 17}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dataset     resource    pipeline        name  pca  \\\n",
       "40      Between2KmsAnd25Kms  memory_mean  continuous         knn   60   \n",
       "42      Between2KmsAnd25Kms  memory_mean  continuous  elasticnet   57   \n",
       "43      Between2KmsAnd25Kms  memory_mean  continuous         svr   33   \n",
       "90                      All  memory_mean  continuous  elasticnet   65   \n",
       "64  ExecutedMoreThan3Ktimes  memory_mean  continuous         knn   13   \n",
       "88                      All  memory_mean  continuous         knn   26   \n",
       "91                      All  memory_mean  continuous         svr   36   \n",
       "41      Between2KmsAnd25Kms  memory_mean  continuous       lasso   42   \n",
       "66  ExecutedMoreThan3Ktimes  memory_mean  continuous  elasticnet   40   \n",
       "67  ExecutedMoreThan3Ktimes  memory_mean  continuous         svr   19   \n",
       "89                      All  memory_mean  continuous       lasso   22   \n",
       "65  ExecutedMoreThan3Ktimes  memory_mean  continuous       lasso   29   \n",
       "16        ShorterThan1.2Kms  memory_mean  continuous         knn   10   \n",
       "18        ShorterThan1.2Kms  memory_mean  continuous  elasticnet   52   \n",
       "19        ShorterThan1.2Kms  memory_mean  continuous         svr   26   \n",
       "17        ShorterThan1.2Kms  memory_mean  continuous       lasso   17   \n",
       "\n",
       "    adjusted_r2    r2   mae  mape  best_score  \\\n",
       "40         0.81  0.82  0.09  0.86        0.81   \n",
       "42         0.80  0.81  0.10  0.95        0.80   \n",
       "43         0.81  0.81  0.10  0.96        0.80   \n",
       "90         0.74  0.74  0.11  2.11        0.73   \n",
       "64         0.73  0.73  0.11  2.09        0.72   \n",
       "88         0.73  0.73  0.11  1.92        0.73   \n",
       "91         0.73  0.73  0.11  2.02        0.73   \n",
       "41         0.70  0.71  0.13  1.29        0.71   \n",
       "66         0.71  0.71  0.12  2.33        0.71   \n",
       "67         0.70  0.70  0.12  2.29        0.70   \n",
       "89         0.69  0.69  0.13  2.32        0.68   \n",
       "65         0.68  0.68  0.13  2.56        0.67   \n",
       "16         0.57  0.57  0.14  2.36        0.55   \n",
       "18         0.56  0.56  0.15  2.64        0.55   \n",
       "19         0.56  0.56  0.15  2.53        0.55   \n",
       "17         0.53  0.53  0.16  2.75        0.53   \n",
       "\n",
       "                                               params  \n",
       "40   {'knn__n_neighbors': 4, 'pca__n_components': 60}  \n",
       "42  {'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...  \n",
       "43  {'pca__n_components': 33, 'svr__alpha': 0.0101...  \n",
       "90  {'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...  \n",
       "64  {'knn__n_neighbors': 13, 'pca__n_components': 13}  \n",
       "88   {'knn__n_neighbors': 6, 'pca__n_components': 26}  \n",
       "91  {'pca__n_components': 36, 'svr__alpha': 0.0001...  \n",
       "41    {'lasso__alpha': 0.01, 'pca__n_components': 42}  \n",
       "66  {'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...  \n",
       "67  {'pca__n_components': 19, 'svr__alpha': 0.1201...  \n",
       "89    {'lasso__alpha': 0.01, 'pca__n_components': 22}  \n",
       "65    {'lasso__alpha': 0.01, 'pca__n_components': 29}  \n",
       "16  {'knn__n_neighbors': 10, 'pca__n_components': 10}  \n",
       "18  {'elasticnet__alpha': 0.060000000000000005, 'e...  \n",
       "19  {'pca__n_components': 26, 'svr__alpha': 0.0901...  \n",
       "17    {'lasso__alpha': 0.01, 'pca__n_components': 17}  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2a_df.loc[exp2a_df.resource == 'memory_mean'].sort_values(\"r2\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>resource</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>name</th>\n",
       "      <th>pca</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Between2KmsAnd25Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>mlp</td>\n",
       "      <td>49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__hidden_l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Between2KmsAnd25Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>knn</td>\n",
       "      <td>52</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>{'knn__n_neighbors': 12, 'pca__n_components': 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Between2KmsAnd25Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>svc</td>\n",
       "      <td>37</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>{'pca__n_components': 37, 'svc__C': 0.5, 'svc_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>All</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>mlp</td>\n",
       "      <td>59</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__hidden_l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ExecutedMoreThan3Ktimes</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>mlp</td>\n",
       "      <td>31</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__hidden_l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>All</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>knn</td>\n",
       "      <td>37</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>{'knn__n_neighbors': 8, 'pca__n_components': 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>All</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>svc</td>\n",
       "      <td>43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.40</td>\n",
       "      <td>{'pca__n_components': 43, 'svc__C': 0.4, 'svc_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ExecutedMoreThan3Ktimes</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>knn</td>\n",
       "      <td>39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>{'knn__n_neighbors': 14, 'pca__n_components': 39}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ExecutedMoreThan3Ktimes</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>svc</td>\n",
       "      <td>30</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.40</td>\n",
       "      <td>{'pca__n_components': 30, 'svc__C': 0.30000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ShorterThan1.2Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>mlp</td>\n",
       "      <td>36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>{'mlp__activation': 'logistic', 'mlp__hidden_l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ShorterThan1.2Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>knn</td>\n",
       "      <td>16</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>{'knn__n_neighbors': 12, 'pca__n_components': 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ShorterThan1.2Kms</td>\n",
       "      <td>memory_mean</td>\n",
       "      <td>classifier_10</td>\n",
       "      <td>svc</td>\n",
       "      <td>36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'pca__n_components': 36, 'svc__C': 0.70000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dataset     resource       pipeline name  pca  accuracy  \\\n",
       "31      Between2KmsAnd25Kms  memory_mean  classifier_10  mlp   49      0.51   \n",
       "30      Between2KmsAnd25Kms  memory_mean  classifier_10  knn   52      0.49   \n",
       "32      Between2KmsAnd25Kms  memory_mean  classifier_10  svc   37      0.49   \n",
       "67                      All  memory_mean  classifier_10  mlp   59      0.48   \n",
       "49  ExecutedMoreThan3Ktimes  memory_mean  classifier_10  mlp   31      0.47   \n",
       "66                      All  memory_mean  classifier_10  knn   37      0.47   \n",
       "68                      All  memory_mean  classifier_10  svc   43      0.47   \n",
       "48  ExecutedMoreThan3Ktimes  memory_mean  classifier_10  knn   39      0.46   \n",
       "50  ExecutedMoreThan3Ktimes  memory_mean  classifier_10  svc   30      0.44   \n",
       "13        ShorterThan1.2Kms  memory_mean  classifier_10  mlp   36      0.35   \n",
       "12        ShorterThan1.2Kms  memory_mean  classifier_10  knn   16      0.34   \n",
       "14        ShorterThan1.2Kms  memory_mean  classifier_10  svc   36      0.34   \n",
       "\n",
       "    balanced_accuracy  f1_micro  f1_macro  \\\n",
       "31               0.50      0.51      0.49   \n",
       "30               0.49      0.49      0.48   \n",
       "32               0.49      0.49      0.49   \n",
       "67               0.44      0.48      0.43   \n",
       "49               0.47      0.47      0.45   \n",
       "66               0.43      0.47      0.42   \n",
       "68               0.42      0.47      0.40   \n",
       "48               0.46      0.46      0.45   \n",
       "50               0.44      0.44      0.40   \n",
       "13               0.32      0.35      0.30   \n",
       "12               0.31      0.34      0.30   \n",
       "14               0.31      0.34      0.25   \n",
       "\n",
       "                                               params  \n",
       "31  {'mlp__activation': 'logistic', 'mlp__hidden_l...  \n",
       "30  {'knn__n_neighbors': 12, 'pca__n_components': 52}  \n",
       "32  {'pca__n_components': 37, 'svc__C': 0.5, 'svc_...  \n",
       "67  {'mlp__activation': 'logistic', 'mlp__hidden_l...  \n",
       "49  {'mlp__activation': 'logistic', 'mlp__hidden_l...  \n",
       "66   {'knn__n_neighbors': 8, 'pca__n_components': 37}  \n",
       "68  {'pca__n_components': 43, 'svc__C': 0.4, 'svc_...  \n",
       "48  {'knn__n_neighbors': 14, 'pca__n_components': 39}  \n",
       "50  {'pca__n_components': 30, 'svc__C': 0.30000000...  \n",
       "13  {'mlp__activation': 'logistic', 'mlp__hidden_l...  \n",
       "12  {'knn__n_neighbors': 12, 'pca__n_components': 16}  \n",
       "14  {'pca__n_components': 36, 'svc__C': 0.70000000...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2b_df.loc[exp2b_df.resource == 'memory_mean'].sort_values(\"accuracy\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
