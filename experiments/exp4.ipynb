{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to build sklearn-like pipeline for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd         \n",
    "import os.path\n",
    "\n",
    "N_JOBS = 6\n",
    "DEBUG=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path=\"../../data/csv/all.csv\"):\n",
    "    dataframe = pd.read_csv(path, index_col=0)\n",
    "    return dataframe.loc[~dataframe[\"execTimeMs\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(dataframe):\n",
    "    output = dataframe.dropna(axis=\"columns\")\n",
    "    targets = output[\"execTimeMs\"]\n",
    "    dropped = output[[\"command\", \"execTimeMs\", \"jobId\", \"ctime_mean\", \"ctime_max\", \"ctime_sum\", \"read_sum\",\"write_sum\",\"readSyscalls_sum\",\"writeSyscalls_sum\",\"readReal_sum\",\"writeReal_sum\",\"writeCancelled_sum\",\"rxBytes_sum\",\"rxPackets_sum\",\"rxErrors_sum\",\"rxDrop_sum\",\"rxFifo_sum\",\"rxFrame_sum\",\"rxCompressed_sum\",\"rxMulticast_sum\",\"txBytes_sum\",\"txPackets_sum\",\"txErrors_sum\",\"txDrop_sum\",\"txFifo_sum\",\"txColls_sum\",\"txCarrier_sum\",\"txCompressed_sum\",\"cpu_mean\",\"cpu_max\",\"memory_mean\",\"memory_max\"]]\n",
    "    features = output.drop(dropped.columns, axis=1)\n",
    "    return features, targets, dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets, dropped = prepare_dataframe(load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workflowName          object\n",
       "size                 float64\n",
       "executable            object\n",
       "args                  object\n",
       "inputs                object\n",
       "outputs               object\n",
       "name                  object\n",
       "cpu.manufacturer      object\n",
       "cpu.brand             object\n",
       "cpu.speed            float64\n",
       "cpu.cores              int64\n",
       "cpu.physicalCores      int64\n",
       "cpu.processors         int64\n",
       "mem.total              int64\n",
       "mem.free               int64\n",
       "mem.used               int64\n",
       "mem.active             int64\n",
       "mem.available          int64\n",
       "mem.buffers            int64\n",
       "mem.cached             int64\n",
       "mem.slab               int64\n",
       "mem.buffcache          int64\n",
       "mem.swaptotal          int64\n",
       "mem.swapused           int64\n",
       "mem.swapfree           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector as selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_list(series):\n",
    "    def vectorize(list_string):\n",
    "        return len(eval(list_string))\n",
    "    return np.vectorize(vectorize)(series)\n",
    "\n",
    "def ListTransformer():\n",
    "    return FunctionTransformer(func=vectorize_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_transformer = Pipeline(steps=[(\"list\", ListTransformer()), (\"scaler\", StandardScaler())])\n",
    "list_features = list(['args', 'inputs', 'outputs'])\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "numerical_features = list(features.select_dtypes(include=\"number\").columns)\n",
    "\n",
    "categorical_transformer = OneHotEncoder(sparse=False, handle_unknown = \"ignore\")\n",
    "categorical_features = list(set(features.select_dtypes(include=\"object\").columns) ^ set(list_features))\n",
    "\n",
    "def make_classifying_preprocessor(additional_features=[\"read_sum\", \"write_sum\", \"cpu_mean\", \"memory_max\"]):\n",
    "    external_features = categorical_features + additional_features\n",
    "    return ColumnTransformer(\n",
    "            transformers=[('lists', list_transformer, list_features), \n",
    "                          ('num', numerical_transformer, numerical_features),\n",
    "                          ('cat', categorical_transformer, external_features)])\n",
    "\n",
    "def make_regression_preprocessor(additional_features=[\"read_sum\", \"write_sum\", \"cpu_mean\", \"memory_max\"]):\n",
    "    external_features = numerical_features + additional_features\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('lists', list_transformer, list_features),            \n",
    "            ('num', numerical_transformer, external_features),  \n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "preprocessor = make_classifying_preprocessor(additional_features=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import percentileofscore\n",
    "import math\n",
    "\n",
    "def calculate_quantile_rank(labels, label):\n",
    "    return percentileofscore(labels, label) / 100\n",
    "\n",
    "def calculate_utilization_class(labels, label):\n",
    "    def label_for_rank(rank):\n",
    "        if rank > 0.75:\n",
    "            return 'very high'\n",
    "        elif rank > 0.5:\n",
    "            return 'high'\n",
    "        elif rank > 0.25:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'low'\n",
    "    return label_for_rank(calculate_quantile_rank(labels, label))\n",
    "\n",
    "def calculate_utilization_bucket(labels, label, num_buckets):\n",
    "    bucket_size = 1.0 / num_buckets\n",
    "    def bucket_for_rank(rank):\n",
    "        return str(math.floor(rank / bucket_size))\n",
    "    return bucket_for_rank(calculate_quantile_rank(labels, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline composition (with PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.linear_model import Lasso, SGDRegressor, ElasticNet, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, HalvingGridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_steps = [('pca', PCA(random_state=42))]\n",
    "dummy_pipeline = Pipeline(steps=base_steps +[('dummy', DummyRegressor())])\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_param_grid = {\n",
    "    'pca__n_components': np.arange(1, 50, 1),    \n",
    "}\n",
    "knn_param_grid = {\n",
    "    'knn__n_neighbors': np.arange(1, 30, 3),\n",
    "}\n",
    "regressor = ('knn', KNeighborsRegressor())\n",
    "full_pipeline = Pipeline(steps= base_steps + [regressor])\n",
    "grid_search = HalvingGridSearchCV(full_pipeline, {**knn_param_grid, **pca_param_grid}, cv=2, verbose=2, scoring=\"r2\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rae(actual, predicted):\n",
    "    \"\"\" Relative Absolute Error (aka Approximation Error) \"\"\"\n",
    "    EPSILON=1e-10\n",
    "    return np.sum(np.abs(actual - predicted)) / (np.sum(np.abs(actual - np.mean(actual))) + EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rae_scorer=make_scorer(rae, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regression_score(true, pred, scores=[r2_score, mean_absolute_error, mean_absolute_percentage_error, rae]):\n",
    "    executor = get_reusable_executor(max_workers=4)\n",
    "    results = executor.map(lambda fun: fun(true, pred), scores)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loky import get_reusable_executor\n",
    "\n",
    "def rate_regressor(X_train, y_train, X_test, y_test, regressor, regressor_params, verbose=10, aggressive_elimination=True, steps=base_steps, scoring=\"r2\"):\n",
    "    if DEBUG:\n",
    "        print(f\"Rating {regressor}\")\n",
    "    full_pipeline = Pipeline(steps= base_steps + [regressor])\n",
    "    vector_length = X_train.shape[1]\n",
    "    pca_param_grid = {'pca__n_components': np.arange(1, vector_length, 1),}\n",
    "    grid_search = HalvingGridSearchCV(full_pipeline, {**pca_param_grid, **regressor_params}, cv=2, verbose=verbose, scoring=scoring, n_jobs=N_JOBS)\n",
    "    if DEBUG:\n",
    "        print(\"Evaluating grid search\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # scores\n",
    "    if DEBUG:\n",
    "        print(\"Predicting on test set\")\n",
    "    prediction = grid_search.best_estimator_.predict(X_test)\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"Calculating scores\")\n",
    "    r2, mae, mape, rae = calculate_regression_score(y_test, prediction)\n",
    "    if DEBUG:\n",
    "        print(\"Calculated scores on test set\")\n",
    "    adjusted_r2 = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "    return {\"r2\": r2, \"adjusted_r2\": adjusted_r2, \"mae\": mae, \"mape\": mape, \"rae\": rae,\"best_score\": grid_search.best_score_, \"params\": grid_search.best_params_}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here go regressor params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = (\"knn\", KNeighborsRegressor())\n",
    "knn_params = {'knn__n_neighbors': np.arange(1, 40, 1)}\n",
    "\n",
    "dtr = (\"dtr\", DecisionTreeRegressor(random_state=5))\n",
    "dtr_params = {\"dtr__criterion\": [\"mse\", \"friedman_mse\", \"mae\", \"poisson\"]}\n",
    "\n",
    "lasso = (\"lasso\", Lasso(random_state=5))\n",
    "lasso_params = {\"lasso__alpha\": np.arange(0.01, 1, 0.05)}\n",
    "\n",
    "en = (\"elasticnet\", ElasticNet(random_state=5))\n",
    "en_params = {\"elasticnet__alpha\": np.arange(0.01, 1, 0.05), \"elasticnet__l1_ratio\": np.arange(0, 1, 0.1)}\n",
    "\n",
    "svr = (\"svr\", SGDRegressor())\n",
    "svr_params = {\"svr__loss\": [\"squared_loss\", \"huber\", \"epsilon_insensitive\"], \"svr__penalty\": ['l2', 'l1', 'elasticnet'],\n",
    "             \"svr__alpha\": np.arange(0.0001, 0.2, 0.01), \"svr__max_iter\": [10000]}\n",
    "\n",
    "rf = (\"rf\", RandomForestRegressor())\n",
    "rf_params = {\"rf__n_estimators\": np.arange(5, 100, 5), \"rf__criterion\": [\"mae\", \"mse\"], \"rf__max_features\": [\"auto\", \"sqrt\", \"log2\"]}\n",
    "\n",
    "kr = (\"kr\", KernelRidge())\n",
    "kr_params = {\"kr__gamma\": np.arange(0.1, 1, 0.05), \"kr__alpha\": np.arange(0.1, 1, 0.05) ,\"kr__kernel\": [\"linear\", \"rbf\", \"sigmoid\", \"polynomial\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_data(features, targets, regressors, verbose=10, pipeline_steps=base_steps):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, random_state=0)\n",
    "    df = pd.DataFrame(columns=[\"name\", \"pca\", \"adjusted_r2\",\"r2\", \"mae\", \"mape\", \"rae\", \"best_score\", \"params\"])\n",
    "    for (regressor, params) in regressors:\n",
    "        result = rate_regressor(X_train, y_train, X_test, y_test, regressor, params, verbose, pipeline_steps)\n",
    "        df = df.append({\"name\": regressor[0], **result, \"pca\": result[\"params\"][\"pca__n_components\"]}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_data_explicit(X_train, X_test, y_train, y_test, regressors, verbose=10, pipeline_steps=base_steps, scoring=\"r2\"):\n",
    "    df = pd.DataFrame(columns=[\"name\", \"pca\", \"adjusted_r2\",\"r2\", \"mae\", \"mape\", \"best_score\", \"params\"])\n",
    "    for (regressor, params) in regressors:\n",
    "        result = rate_regressor(X_train, y_train, X_test, y_test, regressor, params, verbose, pipeline_steps, scoring=scoring)\n",
    "        df = df.append({\"name\": regressor[0], **result, \"pca\": result[\"params\"][\"pca__n_components\"]}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_classifiers_for_data(features, targets, classifiers, verbose=10, pipeline_steps=base_steps):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, random_state=0)\n",
    "    df = pd.DataFrame(columns=[\"name\", \"pca\", \"accuracy\",\"balanced_accuracy\", \"f1_micro\", \"f1_macro\", \"params\"])\n",
    "    for (classifier, params) in classifiers:\n",
    "        result = rate_classifier(X_train, y_train, X_test, y_test, classifier, params, verbose, pipeline_steps)\n",
    "        df = df.append({\"name\": classifier[0], **result, \"pca\": result[\"params\"][\"pca__n_components\"]}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_dataset(dataframe, regressors, verbose=2):\n",
    "    print(f\"Rating dataset of len {len(dataframe)}\")\n",
    "    features, targets, _ = prepare_dataframe(dataframe[:10000])\n",
    "    features = preprocessor.fit_transform(features)\n",
    "    rate_data(features, targets, regressors, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_regressors = [\n",
    "    (knn, knn_params),\n",
    "    (dtr, dtr_params),\n",
    "    (lasso, lasso_params),\n",
    "    (en, en_params),\n",
    "    (svr, svr_params),\n",
    "#     (kr, kr_params),\n",
    "#     (rf, rf_params)\n",
    "]\n",
    "\n",
    "memory_intensive_regressors = [\n",
    "    (kr, kr_params),\n",
    "    (rf, rf_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_experiment():\n",
    "    print(\"Rating jobs datasets\")\n",
    "    for dataset in dfs_for_jobs:\n",
    "        print(dataset.iloc[0][\"name\"])\n",
    "        rate_dataset(dataset, basic_regressors)\n",
    "\n",
    "    print(\"Rating common datasets\")\n",
    "    for dataset in datasets:\n",
    "        rate_dataset(dataset, basic_regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rate_dataset(dfs_for_jobs[8], verbose=0)\n",
    "# rate_dataset(dfs_for_jobs[1], basic_regressors, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperyment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmierzyć skuteczności najlepszych pipelinów dla każdego joba, zobaczyć czy warto schodzić w dół pod wzgledem błędów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = load_data().dropna(axis=\"columns\")\n",
    "raw_datasets = { x:pd.DataFrame(y) for x, y in full_df.groupby('name', as_index=False)}\n",
    "datasets_split = {x:train_test_split(df, random_state=0, train_size=0.75) for x,df in raw_datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_pipeline_data_big(data, resources=[\"read_sum\", \"write_sum\", \"cpu_mean\", \"memory_max\"]):\n",
    "    \"\"\"\n",
    "    Raw data enhanced with resource utilization quantile scores, but scores are assigned - not predicted\n",
    "    \"\"\"\n",
    "    features, labels, dropped = prepare_dataframe(data)\n",
    "    for resource in resources:\n",
    "        features[resource] = dropped[resource].map(lambda value: calculate_quantile_rank(dropped[resource], value))\n",
    "    features = make_regression_preprocessor(resources).fit_transform(features)\n",
    "    return pd.DataFrame(features, index=labels.index), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_pipeline_data_big(data, resources=[\"read_sum\", \"write_sum\", \"cpu_mean\", \"memory_max\"]):\n",
    "    features, labels, dropped = prepare_dataframe(data)\n",
    "    for resource in resources:\n",
    "        features[resource] = dropped[resource].map(lambda value: calculate_utilization_bucket(dropped[resource], value, num_buckets=8))\n",
    "    features = make_classifying_preprocessor(resources).fit_transform(features)\n",
    "    return pd.DataFrame(features, index=labels.index), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobId</th>\n",
       "      <th>read_sum</th>\n",
       "      <th>write_sum</th>\n",
       "      <th>readSyscalls_sum</th>\n",
       "      <th>writeSyscalls_sum</th>\n",
       "      <th>readReal_sum</th>\n",
       "      <th>writeReal_sum</th>\n",
       "      <th>writeCancelled_sum</th>\n",
       "      <th>rxBytes_sum</th>\n",
       "      <th>rxPackets_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>mem.used</th>\n",
       "      <th>mem.active</th>\n",
       "      <th>mem.available</th>\n",
       "      <th>mem.buffers</th>\n",
       "      <th>mem.cached</th>\n",
       "      <th>mem.slab</th>\n",
       "      <th>mem.buffcache</th>\n",
       "      <th>mem.swaptotal</th>\n",
       "      <th>mem.swapused</th>\n",
       "      <th>mem.swapfree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15540</th>\n",
       "      <td>5VzTEh48X-1-8</td>\n",
       "      <td>409532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13633937408</td>\n",
       "      <td>5642911744</td>\n",
       "      <td>27716104192</td>\n",
       "      <td>2768896</td>\n",
       "      <td>6641188864</td>\n",
       "      <td>1846169600</td>\n",
       "      <td>8490127360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86402</th>\n",
       "      <td>YrmwF3UAW-1-320</td>\n",
       "      <td>448476.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6938828800</td>\n",
       "      <td>3055312896</td>\n",
       "      <td>13768790016</td>\n",
       "      <td>315117568</td>\n",
       "      <td>3270520832</td>\n",
       "      <td>713506816</td>\n",
       "      <td>4299145216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58973</th>\n",
       "      <td>yXB4dcCCr-1-34</td>\n",
       "      <td>241751.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28672.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1270759424</td>\n",
       "      <td>788201472</td>\n",
       "      <td>7468998656</td>\n",
       "      <td>454656</td>\n",
       "      <td>577638400</td>\n",
       "      <td>177721344</td>\n",
       "      <td>755814400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110321</th>\n",
       "      <td>uwu6POi40-1-8</td>\n",
       "      <td>426355.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9407356928</td>\n",
       "      <td>1177980928</td>\n",
       "      <td>15646105600</td>\n",
       "      <td>97316864</td>\n",
       "      <td>8047538176</td>\n",
       "      <td>480485376</td>\n",
       "      <td>8625340416</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41349</th>\n",
       "      <td>bcKUGiUAf-1-112</td>\n",
       "      <td>428460.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11516.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10568097792</td>\n",
       "      <td>3031588864</td>\n",
       "      <td>30327427072</td>\n",
       "      <td>2768896</td>\n",
       "      <td>6220783616</td>\n",
       "      <td>1854623744</td>\n",
       "      <td>8078176256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126832</th>\n",
       "      <td>NibmYG_N3-1-34</td>\n",
       "      <td>446548.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13686.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8767651840</td>\n",
       "      <td>1390714880</td>\n",
       "      <td>14376423424</td>\n",
       "      <td>342212608</td>\n",
       "      <td>6592135168</td>\n",
       "      <td>897110016</td>\n",
       "      <td>7831457792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58434</th>\n",
       "      <td>ySTPaOAXY-1-164</td>\n",
       "      <td>316111.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3617013760</td>\n",
       "      <td>1105604608</td>\n",
       "      <td>7151595520</td>\n",
       "      <td>2768896</td>\n",
       "      <td>2224361472</td>\n",
       "      <td>593780736</td>\n",
       "      <td>2820911104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83370</th>\n",
       "      <td>P2WYkNQ_Y-1-8</td>\n",
       "      <td>469391.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13622.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8932556800</td>\n",
       "      <td>3431043072</td>\n",
       "      <td>13393043456</td>\n",
       "      <td>123502592</td>\n",
       "      <td>5412884480</td>\n",
       "      <td>364777472</td>\n",
       "      <td>5901164544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74809</th>\n",
       "      <td>DayfX-Qsv-1-86</td>\n",
       "      <td>414077.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8723546112</td>\n",
       "      <td>1424261120</td>\n",
       "      <td>15399841792</td>\n",
       "      <td>340754432</td>\n",
       "      <td>6542303232</td>\n",
       "      <td>907046912</td>\n",
       "      <td>7790104576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110369</th>\n",
       "      <td>v1v9LgqQ6-1-34</td>\n",
       "      <td>327614.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5919141888</td>\n",
       "      <td>1399324672</td>\n",
       "      <td>15424778240</td>\n",
       "      <td>340844544</td>\n",
       "      <td>3767300096</td>\n",
       "      <td>904417280</td>\n",
       "      <td>5012561920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  jobId  read_sum  write_sum  readSyscalls_sum  \\\n",
       "15540     5VzTEh48X-1-8  409532.0        9.0             305.0   \n",
       "86402   YrmwF3UAW-1-320  448476.0        9.0             359.0   \n",
       "58973    yXB4dcCCr-1-34  241751.0        9.0             192.0   \n",
       "110321    uwu6POi40-1-8  426355.0        9.0             316.0   \n",
       "41349   bcKUGiUAf-1-112  428460.0        9.0             321.0   \n",
       "...                 ...       ...        ...               ...   \n",
       "126832   NibmYG_N3-1-34  446548.0       19.0             356.0   \n",
       "58434   ySTPaOAXY-1-164  316111.0        9.0             247.0   \n",
       "83370     P2WYkNQ_Y-1-8  469391.0       19.0             391.0   \n",
       "74809    DayfX-Qsv-1-86  414077.0        9.0             308.0   \n",
       "110369   v1v9LgqQ6-1-34  327614.0        9.0             253.0   \n",
       "\n",
       "        writeSyscalls_sum  readReal_sum  writeReal_sum  writeCancelled_sum  \\\n",
       "15540                 9.0           0.0        32768.0                 0.0   \n",
       "86402                 9.0           0.0        32768.0                 0.0   \n",
       "58973                 9.0       28672.0        32768.0                 0.0   \n",
       "110321                9.0           0.0        32768.0                 0.0   \n",
       "41349                 9.0           0.0        32768.0                 0.0   \n",
       "...                   ...           ...            ...                 ...   \n",
       "126832               10.0           0.0        32768.0                 0.0   \n",
       "58434                 9.0           0.0        32768.0                 0.0   \n",
       "83370                10.0           0.0        32768.0                 0.0   \n",
       "74809                 9.0           0.0        32768.0                 0.0   \n",
       "110369                9.0           0.0        32768.0                 0.0   \n",
       "\n",
       "        rxBytes_sum  rxPackets_sum  ...     mem.used  mem.active  \\\n",
       "15540           0.0            0.0  ...  13633937408  5642911744   \n",
       "86402       14300.0           60.0  ...   6938828800  3055312896   \n",
       "58973           0.0            0.0  ...   1270759424   788201472   \n",
       "110321          0.0            0.0  ...   9407356928  1177980928   \n",
       "41349       11516.0           29.0  ...  10568097792  3031588864   \n",
       "...             ...            ...  ...          ...         ...   \n",
       "126832      13686.0           46.0  ...   8767651840  1390714880   \n",
       "58434           0.0            0.0  ...   3617013760  1105604608   \n",
       "83370       13622.0           51.0  ...   8932556800  3431043072   \n",
       "74809           0.0            0.0  ...   8723546112  1424261120   \n",
       "110369          0.0            0.0  ...   5919141888  1399324672   \n",
       "\n",
       "        mem.available  mem.buffers  mem.cached    mem.slab  mem.buffcache  \\\n",
       "15540     27716104192      2768896  6641188864  1846169600     8490127360   \n",
       "86402     13768790016    315117568  3270520832   713506816     4299145216   \n",
       "58973      7468998656       454656   577638400   177721344      755814400   \n",
       "110321    15646105600     97316864  8047538176   480485376     8625340416   \n",
       "41349     30327427072      2768896  6220783616  1854623744     8078176256   \n",
       "...               ...          ...         ...         ...            ...   \n",
       "126832    14376423424    342212608  6592135168   897110016     7831457792   \n",
       "58434      7151595520      2768896  2224361472   593780736     2820911104   \n",
       "83370     13393043456    123502592  5412884480   364777472     5901164544   \n",
       "74809     15399841792    340754432  6542303232   907046912     7790104576   \n",
       "110369    15424778240    340844544  3767300096   904417280     5012561920   \n",
       "\n",
       "        mem.swaptotal  mem.swapused  mem.swapfree  \n",
       "15540               0             0             0  \n",
       "86402               0             0             0  \n",
       "58973               0             0             0  \n",
       "110321              0             0             0  \n",
       "41349               0             0             0  \n",
       "...               ...           ...           ...  \n",
       "126832              0             0             0  \n",
       "58434               0             0             0  \n",
       "83370               0             0             0  \n",
       "74809               0             0             0  \n",
       "110369              0             0             0  \n",
       "\n",
       "[122 rows x 58 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_split['add_replace'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przebieg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trenujemy pipeline ogólny, liczymy jego skuteczności dla każdego typu jobów. Z eksperymentu 1. - najlepszy pipeline to był:\n",
    "\n",
    "dtr, mae, pca 71\n",
    "\n",
    "dla każdego typu jobów trenujemy dla niego pipeline, liczymy skuteczności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = datasets_split['add_replace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment4():\n",
    "    exp4_resources = [\"read_sum\", \"write_sum\", \"cpu_max\", \"cpu_mean\", \"memory_mean\", \"memory_max\"]\n",
    "        \n",
    "    big_regressor = Pipeline([ # test pipeline\n",
    "        ('pca', PCA(random_state=42, n_components=71)),\n",
    "#         ('knn', KNeighborsRegressor(n_neighbors=11))\n",
    "        ('dtr', DecisionTreeRegressor(criterion=\"mae\"))\n",
    "    ])\n",
    "    print(\"Preparing data for big regressor\")\n",
    "    X, y = get_numerical_pipeline_data_big(full_df, exp4_resources)\n",
    "    train_indices = np.concatenate([train.index for (_, (train, _)) in datasets_split.items()])\n",
    "    test_indices = np.concatenate([test.index for (_, (_, test)) in datasets_split.items()])\n",
    "    print(f\"{len(X)} {len(y)} {len(train_indices)} {len(test_indices)}\")\n",
    "    X_train, X_test, y_train, y_test = X.loc[train_indices], X.loc[test_indices], y.loc[train_indices], y.loc[test_indices]\n",
    "    print(f\"Making split with test as {len(test_indices)/(len(test_indices) + len(train_indices))} of dataset\")\n",
    "    \n",
    "    print(\"Training big regressor with train data\")\n",
    "    big_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Predicting with big regressor on test data\")\n",
    "    y_predicted = big_regressor.predict(X_test)\n",
    "    \n",
    "    print(\"Rating big regressor's overall performance\")\n",
    "    [r2, mae, mape, rae_score] = calculate_regression_score(y_test, y_predicted, [r2_score, mean_absolute_error, mean_absolute_percentage_error, rae])\n",
    "    print(f\"Scores for big regressor:\")\n",
    "    print(f\"R2: {r2}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MAPE: {mape}\")\n",
    "    print(f\"RAE: {rae_score}\")\n",
    "    print()\n",
    "    dataframes = []\n",
    "    for (job, (train, test)) in datasets_split.items():\n",
    "        print(f\"Comparing big regressor vs local regressor for job {job}\")\n",
    "        print(\"Preparing data for local regressor\")\n",
    "        joint_df = pd.concat([train, test])\n",
    "        local_X, local_y = get_numerical_pipeline_data_big(joint_df, exp4_resources)\n",
    "        print(f\"{len(local_X)} {len(train.index)} {len(test.index)}\")\n",
    "        local_X_train, local_X_test, local_y_train, local_y_test = local_X.loc[train.index], local_X.loc[test.index], local_y.loc[train.index], local_y.loc[test.index]\n",
    "        \n",
    "        print(f\"Rating local regressors for job {job}\")\n",
    "        regressor_df = rate_data_explicit(local_X_train, local_X_test, local_y_train, local_y_test, basic_regressors, verbose=0)\n",
    "        print(regressor_df.head())\n",
    "        print(\"Preparing data for big regressor\")\n",
    "        local_X_test, local_y_test = X.loc[test.index], y.loc[test.index]\n",
    "        \n",
    "        print(f\"Rating big regressor for job {job}\")\n",
    "        local_predicted = big_regressor.predict(local_X_test)\n",
    "        [r2, mae, mape, rae_score] = calculate_regression_score(local_predicted, local_y_test, [r2_score, mean_absolute_error, mean_absolute_percentage_error, rae])\n",
    "        regressor_df = regressor_df.append({\"name\": \"big\", **{\"r2\": r2, \"mae\": mae, \"mape\": mape, \"rae\": rae_score}, \"pca\": \"xD\"}, ignore_index=True)\n",
    "        regressor_df[\"job\"] = job\n",
    "        regressor_df[\"size\"] = len(joint_df)\n",
    "        dataframes.append(regressor_df)\n",
    "        \n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment4_memory_intensive():\n",
    "    global N_JOBS\n",
    "    N_JOBS=2\n",
    "    exp4_resources = [\"read_sum\", \"write_sum\", \"cpu_max\", \"cpu_mean\", \"memory_mean\", \"memory_max\"]\n",
    "    train_indices = np.concatenate([train.index for (_, (train, _)) in datasets_split.items()])\n",
    "    test_indices = np.concatenate([test.index for (_, (_, test)) in datasets_split.items()])\n",
    "    dataframes = []\n",
    "    for (job, (train, test)) in datasets_split.items():\n",
    "        print(\"Preparing data for local regressor\")\n",
    "        joint_df = pd.concat([train, test])\n",
    "        local_X, local_y = get_numerical_pipeline_data_big(joint_df, exp4_resources)\n",
    "        print(f\"{len(local_X)} {len(train.index)} {len(test.index)}\")\n",
    "        local_X_train, local_X_test, local_y_train, local_y_test = local_X.loc[train.index], local_X.loc[test.index], local_y.loc[train.index], local_y.loc[test.index]\n",
    "        \n",
    "        print(f\"Rating local regressors for job {job}\")\n",
    "        regressor_df = rate_data_explicit(local_X_train, local_X_test, local_y_train, local_y_test, memory_intensive_regressors, verbose=0)\n",
    "        print(regressor_df.head())\n",
    "        regressor_df[\"job\"] = job\n",
    "        regressor_df[\"size\"] = len(joint_df)\n",
    "        dataframes.append(regressor_df)\n",
    "        \n",
    "    N_JOBS=7\n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment4_categorical():\n",
    "    exp4_resources = [\"read_sum\", \"write_sum\", \"cpu_max\", \"cpu_mean\", \"memory_mean\", \"memory_max\"]\n",
    "    train_indices = np.concatenate([train.index for (_, (train, _)) in datasets_split.items()])\n",
    "    test_indices = np.concatenate([test.index for (_, (_, test)) in datasets_split.items()])\n",
    "    dataframes = []\n",
    "    for (job, (train, test)) in datasets_split.items():\n",
    "        print(\"Preparing data for local regressor\")\n",
    "        joint_df = pd.concat([train, test])\n",
    "        local_X, local_y = get_categorical_pipeline_data_big(joint_df, exp4_resources)\n",
    "        print(f\"{len(local_X)} {len(train.index)} {len(test.index)}\")\n",
    "        local_X_train, local_X_test, local_y_train, local_y_test = local_X.loc[train.index], local_X.loc[test.index], local_y.loc[train.index], local_y.loc[test.index]\n",
    "        \n",
    "        print(f\"Rating local regressors for job {job}\")\n",
    "        regressor_df = rate_data_explicit(local_X_train, local_X_test, local_y_train, local_y_test, basic_regressors, verbose=0)\n",
    "        print(regressor_df.head())\n",
    "        regressor_df[\"job\"] = job\n",
    "        regressor_df[\"size\"] = len(joint_df)\n",
    "        dataframes.append(regressor_df)\n",
    "        \n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment4_numerical_rae():\n",
    "    exp4_resources = [\"read_sum\", \"write_sum\", \"cpu_max\", \"cpu_mean\", \"memory_mean\", \"memory_max\"]\n",
    "        \n",
    "    \n",
    "    train_indices = np.concatenate([train.index for (_, (train, _)) in datasets_split.items()])\n",
    "    test_indices = np.concatenate([test.index for (_, (_, test)) in datasets_split.items()])\n",
    "    dataframes = []\n",
    "    for (job, (train, test)) in datasets_split.items():\n",
    "        print(\"Preparing data for local regressor\")\n",
    "        joint_df = pd.concat([train, test])\n",
    "        local_X, local_y = get_numerical_pipeline_data_big(joint_df, exp4_resources)\n",
    "        print(f\"{len(local_X)} {len(train.index)} {len(test.index)}\")\n",
    "        local_X_train, local_X_test, local_y_train, local_y_test = local_X.loc[train.index], local_X.loc[test.index], local_y.loc[train.index], local_y.loc[test.index]\n",
    "        \n",
    "        print(f\"Rating local regressors for job {job}\")\n",
    "        regressor_df = rate_data_explicit(local_X_train, local_X_test, local_y_train, local_y_test, basic_regressors, verbose=0, scoring=rae_scorer)\n",
    "        print(regressor_df.head())\n",
    "        regressor_df[\"job\"] = job\n",
    "        regressor_df[\"size\"] = len(joint_df)\n",
    "        dataframes.append(regressor_df)\n",
    "        \n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_run(file, runner):\n",
    "    if not os.path.isfile(file):\n",
    "        print(f\"Running experiment {file}\")\n",
    "        dataframe = runner()\n",
    "        dataframe.to_csv(file)\n",
    "    else:\n",
    "        dataframe = pd.read_csv(file).round(2)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4_r2_df_incomplete = load_or_run(\"data/exp4_optimize_r2.csv\", run_experiment4)\n",
    "# exp4_r2_df_memory_intensive = load_or_run(\"data/exp4_optimize_r2_memint.csv\", run_experiment4_memory_intensive)\n",
    "# exp4_r2_categorical_incomplete = load_or_run(\"data/exp4_optimize_r2_categorical.csv\", run_experiment4_categorical)\n",
    "# exp4_rae_incomplete = load_or_run(\"data/exp4_optimize_rae.csv\", run_experiment4_rae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>pca</th>\n",
       "      <th>adjusted_r2</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>best_score</th>\n",
       "      <th>params</th>\n",
       "      <th>rae</th>\n",
       "      <th>job</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>30</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1165.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.97</td>\n",
       "      <td>{'knn__n_neighbors': 6, 'pca__n_components': 30}</td>\n",
       "      <td>0.11</td>\n",
       "      <td>mProject</td>\n",
       "      <td>15294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>28</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>550.37</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.92</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'pca__n_components': 28}</td>\n",
       "      <td>0.13</td>\n",
       "      <td>mBackground</td>\n",
       "      <td>28618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>22</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10728.34</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'pca__n_components': 22}</td>\n",
       "      <td>0.14</td>\n",
       "      <td>genotype_gvcfs</td>\n",
       "      <td>1719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>27</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1172749.10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>merge_gcvf</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>35</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2143.73</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'pca__n_components': 35}</td>\n",
       "      <td>0.19</td>\n",
       "      <td>haplotype_caller</td>\n",
       "      <td>9739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>dtr</td>\n",
       "      <td>20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>11878.61</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.59</td>\n",
       "      <td>{'dtr__criterion': 'friedman_mse', 'pca__n_com...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>realign_target_creator</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>28</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.95</td>\n",
       "      <td>107.69</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>filtering_snp</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>13</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>281.78</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'pca__n_components': 13}</td>\n",
       "      <td>0.23</td>\n",
       "      <td>mDiffFit</td>\n",
       "      <td>109575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>big</td>\n",
       "      <td>xD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.86</td>\n",
       "      <td>221.59</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>combine_variants</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>28</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.89</td>\n",
       "      <td>140.39</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>filtering_indel</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>31</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.63</td>\n",
       "      <td>5617.58</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.48</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'pca__n_components': 31}</td>\n",
       "      <td>0.27</td>\n",
       "      <td>mConcatFit</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>dtr</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5696.39</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>{'dtr__criterion': 'friedman_mse', 'pca__n_com...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>mBgModel</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>30</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>121.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>{'knn__n_neighbors': 11, 'pca__n_components': 30}</td>\n",
       "      <td>0.29</td>\n",
       "      <td>mProjectPP</td>\n",
       "      <td>15536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>8199.68</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.22</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'pca__n_components': 29}</td>\n",
       "      <td>0.31</td>\n",
       "      <td>mAdd</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>28</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3227.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'pca__n_components': 28}</td>\n",
       "      <td>0.31</td>\n",
       "      <td>select_variants_snp</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>dtr</td>\n",
       "      <td>26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1898.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'dtr__criterion': 'friedman_mse', 'pca__n_com...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>mViewer</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1251.93</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.76</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'pca__n_components': 21}</td>\n",
       "      <td>0.32</td>\n",
       "      <td>alignment_to_reference</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>21</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "      <td>435.79</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'pca__n_components': 21}</td>\n",
       "      <td>0.32</td>\n",
       "      <td>dedup</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>26</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.85</td>\n",
       "      <td>45514.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...</td>\n",
       "      <td>0.37</td>\n",
       "      <td>bwa-index</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>dtr</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.53</td>\n",
       "      <td>981.81</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.24</td>\n",
       "      <td>{'dtr__criterion': 'friedman_mse', 'pca__n_com...</td>\n",
       "      <td>0.38</td>\n",
       "      <td>mImgtbl</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>28</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.78</td>\n",
       "      <td>5023.55</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'pca__n_components': 28}</td>\n",
       "      <td>0.45</td>\n",
       "      <td>select_variants_indel</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>30</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.73</td>\n",
       "      <td>842.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'pca__n_components': 30}</td>\n",
       "      <td>0.49</td>\n",
       "      <td>seq_dict</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>knn</td>\n",
       "      <td>28</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.80</td>\n",
       "      <td>849.70</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'knn__n_neighbors': 1, 'pca__n_components': 28}</td>\n",
       "      <td>0.49</td>\n",
       "      <td>faidx</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5</td>\n",
       "      <td>big</td>\n",
       "      <td>xD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3729.23</td>\n",
       "      <td>1.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49</td>\n",
       "      <td>mShrink</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>23</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.78</td>\n",
       "      <td>336.27</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.46</td>\n",
       "      <td>{'elasticnet__alpha': 0.46, 'elasticnet__l1_ra...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>indel_realign</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>5</td>\n",
       "      <td>big</td>\n",
       "      <td>xD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>76.54</td>\n",
       "      <td>0.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.54</td>\n",
       "      <td>sort_sam</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>lasso</td>\n",
       "      <td>18</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.19</td>\n",
       "      <td>83.59</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'lasso__alpha': 0.01, 'pca__n_components': 18}</td>\n",
       "      <td>0.59</td>\n",
       "      <td>mJPEG</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>big</td>\n",
       "      <td>xD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "      <td>102.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>add_replace</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        name pca  adjusted_r2    r2         mae  mape  \\\n",
       "108           0         knn  30         0.98  0.98     1165.78  0.04   \n",
       "72            0         knn  28         0.94  0.94      550.37  0.22   \n",
       "48            0         knn  22         0.97  0.97    10728.34  0.10   \n",
       "135           3  elasticnet  27         1.03  0.97  1172749.10  0.16   \n",
       "54            0         knn  35         0.95  0.95     2143.73  0.04   \n",
       "139           1         dtr  20         0.92  0.94    11878.61  0.07   \n",
       "45            3  elasticnet  28         1.07  0.95      107.69  0.03   \n",
       "90            0         knn  13         0.80  0.80      281.78  0.26   \n",
       "23            5         big  xD          NaN  0.86      221.59  0.05   \n",
       "39            3  elasticnet  28         1.15  0.89      140.39  0.04   \n",
       "84            0         knn  31         0.21  0.63     5617.58  0.33   \n",
       "79            1         dtr  31        -0.42  0.34     5696.39  0.16   \n",
       "114           0         knn  30         0.81  0.82      121.84  0.10   \n",
       "66            0         knn  29         0.30  0.67     8199.68  0.78   \n",
       "150           0         knn  28         1.13  0.90     3227.00  0.07   \n",
       "127           1         dtr  26         0.20  0.70     1898.58  0.45   \n",
       "6             0         knn  21         0.75  0.83     1251.93  0.22   \n",
       "24            0         knn  21         0.71  0.80      435.79  0.07   \n",
       "15            3  elasticnet  26         1.20  0.85    45514.04  0.04   \n",
       "97            1         dtr  18        -0.06  0.53      981.81  1.71   \n",
       "144           0         knn  28         1.29  0.78     5023.55  0.10   \n",
       "156           0         knn  30         1.40  0.73      842.04  0.11   \n",
       "30            0         knn  28         1.29  0.80      849.70  0.16   \n",
       "125           5         big  xD          NaN  0.27     3729.23  1.14   \n",
       "63            3  elasticnet  23         0.68  0.78      336.27  0.09   \n",
       "167           5         big  xD          NaN  0.85       76.54  0.13   \n",
       "104           2       lasso  18         3.93  0.19       83.59  0.08   \n",
       "5             5         big  xD          NaN  0.30      102.21  0.15   \n",
       "\n",
       "     best_score                                             params   rae  \\\n",
       "108        0.97   {'knn__n_neighbors': 6, 'pca__n_components': 30}  0.11   \n",
       "72         0.92   {'knn__n_neighbors': 7, 'pca__n_components': 28}  0.13   \n",
       "48         0.93   {'knn__n_neighbors': 1, 'pca__n_components': 22}  0.14   \n",
       "135         NaN  {'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...  0.14   \n",
       "54         0.93   {'knn__n_neighbors': 3, 'pca__n_components': 35}  0.19   \n",
       "139        0.59  {'dtr__criterion': 'friedman_mse', 'pca__n_com...  0.20   \n",
       "45          NaN  {'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...  0.23   \n",
       "90         0.81   {'knn__n_neighbors': 5, 'pca__n_components': 13}  0.23   \n",
       "23          NaN                                                NaN  0.26   \n",
       "39          NaN  {'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...  0.26   \n",
       "84         0.48   {'knn__n_neighbors': 1, 'pca__n_components': 31}  0.27   \n",
       "79         0.14  {'dtr__criterion': 'friedman_mse', 'pca__n_com...  0.29   \n",
       "114        0.86  {'knn__n_neighbors': 11, 'pca__n_components': 30}  0.29   \n",
       "66         0.22   {'knn__n_neighbors': 1, 'pca__n_components': 29}  0.31   \n",
       "150         NaN   {'knn__n_neighbors': 1, 'pca__n_components': 28}  0.31   \n",
       "127        0.85  {'dtr__criterion': 'friedman_mse', 'pca__n_com...  0.32   \n",
       "6          0.76   {'knn__n_neighbors': 5, 'pca__n_components': 21}  0.32   \n",
       "24         0.69   {'knn__n_neighbors': 5, 'pca__n_components': 21}  0.32   \n",
       "15          NaN  {'elasticnet__alpha': 0.01, 'elasticnet__l1_ra...  0.37   \n",
       "97         0.24  {'dtr__criterion': 'friedman_mse', 'pca__n_com...  0.38   \n",
       "144         NaN   {'knn__n_neighbors': 1, 'pca__n_components': 28}  0.45   \n",
       "156         NaN   {'knn__n_neighbors': 1, 'pca__n_components': 30}  0.49   \n",
       "30          NaN   {'knn__n_neighbors': 1, 'pca__n_components': 28}  0.49   \n",
       "125         NaN                                                NaN  0.49   \n",
       "63         0.46  {'elasticnet__alpha': 0.46, 'elasticnet__l1_ra...  0.50   \n",
       "167         NaN                                                NaN  0.54   \n",
       "104         NaN    {'lasso__alpha': 0.01, 'pca__n_components': 18}  0.59   \n",
       "5           NaN                                                NaN  0.67   \n",
       "\n",
       "                        job    size  \n",
       "108                mProject   15294  \n",
       "72              mBackground   28618  \n",
       "48           genotype_gvcfs    1719  \n",
       "135              merge_gcvf      83  \n",
       "54         haplotype_caller    9739  \n",
       "139  realign_target_creator     487  \n",
       "45            filtering_snp      85  \n",
       "90                 mDiffFit  109575  \n",
       "23         combine_variants      85  \n",
       "39          filtering_indel      85  \n",
       "84               mConcatFit     288  \n",
       "79                 mBgModel     288  \n",
       "114              mProjectPP   15536  \n",
       "66                     mAdd     290  \n",
       "150     select_variants_snp      85  \n",
       "127                 mViewer     226  \n",
       "6    alignment_to_reference     495  \n",
       "24                    dedup     493  \n",
       "15                bwa-index      88  \n",
       "97                  mImgtbl     276  \n",
       "144   select_variants_indel      85  \n",
       "156                seq_dict      89  \n",
       "30                    faidx      90  \n",
       "125                 mShrink     119  \n",
       "63            indel_realign     487  \n",
       "167                sort_sam     495  \n",
       "104                   mJPEG     119  \n",
       "5               add_replace     488  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp4_r2_df_incomplete.sort_values('rae', ascending=True).drop_duplicates(['job'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyniki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykresy:\n",
    "- najlepsza skuteczność regresora (min mape/rae) vs liczba sampli\n",
    "- skuteczności 5 najlepszych regresorów dla każdego (grid chart)\n",
    "- najlepsza skuteczność regresora dla joba vs skuteczność dużego regresora dla tego joba\n",
    "\n",
    "Odpowiedzi:\n",
    "- czy zwiększenie granularności jest sensowne?\n",
    "- czy jest jakiś widoczny próg liczby sampli przy zwiększonej granularności?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
