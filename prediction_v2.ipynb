{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to build sklearn-like pipeline for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path=\"../data/csv/all.csv\"):\n",
    "    dataframe = pd.read_csv(path, index_col=0)[:50000]\n",
    "    return dataframe.loc[~dataframe[\"execTimeMs\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(dataframe):\n",
    "    output = dataframe.dropna(axis=\"columns\")\n",
    "    targets = output[\"execTimeMs\"]\n",
    "    features = output.drop([\"execTimeMs\", \"jobId\", \"ctime_mean\", \"ctime_max\", \"ctime_sum\"], axis=1)\n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets = prepare_dataframe(load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_sum              float64\n",
       "write_sum             float64\n",
       "readSyscalls_sum      float64\n",
       "writeSyscalls_sum     float64\n",
       "readReal_sum          float64\n",
       "writeReal_sum         float64\n",
       "writeCancelled_sum    float64\n",
       "rxBytes_sum           float64\n",
       "rxPackets_sum         float64\n",
       "rxErrors_sum          float64\n",
       "rxDrop_sum            float64\n",
       "rxFifo_sum            float64\n",
       "rxFrame_sum           float64\n",
       "rxCompressed_sum      float64\n",
       "rxMulticast_sum       float64\n",
       "txBytes_sum           float64\n",
       "txPackets_sum         float64\n",
       "txErrors_sum          float64\n",
       "txDrop_sum            float64\n",
       "txFifo_sum            float64\n",
       "txColls_sum           float64\n",
       "txCarrier_sum         float64\n",
       "txCompressed_sum      float64\n",
       "cpu_mean              float64\n",
       "cpu_max               float64\n",
       "memory_mean           float64\n",
       "memory_max            float64\n",
       "workflowName           object\n",
       "size                  float64\n",
       "executable             object\n",
       "args                   object\n",
       "inputs                 object\n",
       "outputs                object\n",
       "name                   object\n",
       "command                object\n",
       "cpu.manufacturer       object\n",
       "cpu.brand              object\n",
       "cpu.speed             float64\n",
       "cpu.cores               int64\n",
       "cpu.physicalCores       int64\n",
       "cpu.processors          int64\n",
       "mem.total               int64\n",
       "mem.free                int64\n",
       "mem.used                int64\n",
       "mem.active              int64\n",
       "mem.available           int64\n",
       "mem.buffers             int64\n",
       "mem.cached              int64\n",
       "mem.slab                int64\n",
       "mem.buffcache           int64\n",
       "mem.swaptotal           int64\n",
       "mem.swapused            int64\n",
       "mem.swapfree            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector as selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_list(series):\n",
    "    def vectorize(list_string):\n",
    "        return len(eval(list_string))\n",
    "    return np.vectorize(vectorize)(series)\n",
    "\n",
    "def ListTransformer():\n",
    "    return FunctionTransformer(func=vectorize_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_features = ['command']\n",
    "\n",
    "list_transformer = Pipeline(steps=[(\"list\", ListTransformer()), (\"scaler\", StandardScaler())])\n",
    "list_features = list(['args', 'inputs', 'outputs'])\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "numerical_features = list(features.select_dtypes(include=\"number\").columns)\n",
    "\n",
    "categorical_transformer = OneHotEncoder(sparse=False, handle_unknown = \"ignore\")\n",
    "categorical_features = list(set(features.select_dtypes(include=\"object\").columns) ^ set(list_features) ^ set(ignored_features))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('lists', list_transformer, list_features),\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline composition (with PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Lasso, SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_steps = [('preprocessor', preprocessor),\n",
    "              ('pca', PCA())]\n",
    "dummy_pipeline = Pipeline(steps=base_steps +[('dummy', DummyRegressor())])\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_param_grid = {\n",
    "    'pca__n_components': np.arange(1, 50, 3),    \n",
    "}\n",
    "knn_param_grid = {\n",
    "    'knn__n_neighbors': np.arange(1, 30, 3),\n",
    "}\n",
    "regressor = ('knn', KNeighborsRegressor())\n",
    "full_pipeline = Pipeline(steps= base_steps + [regressor])\n",
    "grid_search = HalvingGridSearchCV(full_pipeline, {**knn_param_grid, **pca_param_grid}, cv=2, verbose=2, scoring=\"r2\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def rate_regressor(X_train, y_train, X_test, y_test, regressor, regressor_params, aggressive_elimination=True):\n",
    "    full_pipeline = Pipeline(steps= base_steps + [regressor])\n",
    "    pca_param_grid = {    'pca__n_components': np.arange(1, 50, 3),    }\n",
    "    grid_search = HalvingGridSearchCV(full_pipeline, {**pca_param_grid, **regressor_params}, cv=2, verbose=2, scoring=\"r2\", n_jobs=3, aggressive_elimination=aggressive_elimination)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "    print(r2_score(grid_search.best_estimator_.predict(X_test), y_test))\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here go regressor params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = (\"knn\", KNeighborsRegressor())\n",
    "knn_params = {'knn__n_neighbors': np.arange(1, 30, 2)}\n",
    "\n",
    "dtr = (\"dtr\", DecisionTreeRegressor())\n",
    "dtr_params = {\"dtr__criterion\": [\"mse\", \"friedman_mse\", \"mae\", \"poisson\"]}\n",
    "\n",
    "mlp = (\"mlp\", MLPRegressor())\n",
    "mlp_params = {\"mlp__hidden_layer_sizes\": np.arange(1,200, 10),\n",
    "#                 \"mlp__activation\": [\"logistic\", \"tanh\", \"relu\"],\n",
    "             \"mlp__alpha\": np.arange(0.01, 0.1, 0.01)}\n",
    "\n",
    "lasso = (\"lasso\", Lasso())\n",
    "lasso_params = {\"lasso__alpha\": np.arange(0.01, 1, 0.05)}\n",
    "\n",
    "svr = (\"svr\", SGDRegressor())\n",
    "svr_params = {\"svr__loss\": [\"squared_loss\", \"huber\", \"epsilon_insensitive\"], \"svr__penalty\": ['l2', 'l1', 'elasticnet'],\n",
    "             \"svr__alpha\": np.arange(0.0001, 0.2, 0.01), \"svr__max_iter\": [10000]}\n",
    "\n",
    "rf = (\"rf\", RandomForestRegressor())\n",
    "rf_params = {\"rf__n_estimators\": np.arange(5, 100, 5), \"rf__criterion\": [\"mae\", \"mse\"], \"rf__max_features\": [\"auto\", \"sqrt\", \"log2\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 6\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 164\n",
      "max_resources_: 39998\n",
      "aggressive_elimination: True\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 255\n",
      "n_resources: 164\n",
      "Fitting 2 folds for each of 255 candidates, totalling 510 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 85\n",
      "n_resources: 164\n",
      "Fitting 2 folds for each of 85 candidates, totalling 170 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 29\n",
      "n_resources: 492\n",
      "Fitting 2 folds for each of 29 candidates, totalling 58 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 10\n",
      "n_resources: 1476\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 4\n",
      "n_resources: 4428\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 2\n",
      "n_resources: 13284\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "0.2169224587779534\n",
      "{'knn__n_neighbors': 1, 'pca__n_components': 31}\n",
      "0.6943388908256861\n"
     ]
    }
   ],
   "source": [
    "knn_cv = rate_regressor(X_train, y_train, X_test, y_test, knn, knn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 1481\n",
      "max_resources_: 39998\n",
      "aggressive_elimination: True\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 68\n",
      "n_resources: 1481\n",
      "Fitting 2 folds for each of 68 candidates, totalling 136 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 23\n",
      "n_resources: 4443\n",
      "Fitting 2 folds for each of 23 candidates, totalling 46 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 8\n",
      "n_resources: 13329\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 39987\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "0.734967982694674\n",
      "{'dtr__criterion': 'poisson', 'pca__n_components': 28}\n",
      "0.6959232741766164\n"
     ]
    }
   ],
   "source": [
    "dtr_cv = rate_regressor(X_train, y_train, X_test, y_test, dtr, dtr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 8\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 8\n",
      "min_resources_: 18\n",
      "max_resources_: 39998\n",
      "aggressive_elimination: True\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 3060\n",
      "n_resources: 18\n",
      "Fitting 2 folds for each of 3060 candidates, totalling 6120 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 1020\n",
      "n_resources: 54\n",
      "Fitting 2 folds for each of 1020 candidates, totalling 2040 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 340\n",
      "n_resources: 162\n",
      "Fitting 2 folds for each of 340 candidates, totalling 680 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 114\n",
      "n_resources: 486\n",
      "Fitting 2 folds for each of 114 candidates, totalling 228 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 38\n",
      "n_resources: 1458\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 13\n",
      "n_resources: 4374\n",
      "Fitting 2 folds for each of 13 candidates, totalling 26 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 5\n",
      "n_resources: 13122\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "----------\n",
      "iter: 7\n",
      "n_candidates: 2\n",
      "n_resources: 39366\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "0.2183548684241109\n",
      "{'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 191, 'pca__n_components': 28}\n",
      "-251.84368644855536\n"
     ]
    }
   ],
   "source": [
    "mlp_cv = rate_regressor(X_train, y_train, X_test, y_test, mlp, mlp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 6\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 164\n",
      "max_resources_: 39998\n",
      "aggressive_elimination: True\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 340\n",
      "n_resources: 164\n",
      "Fitting 2 folds for each of 340 candidates, totalling 680 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 114\n",
      "n_resources: 164\n",
      "Fitting 2 folds for each of 114 candidates, totalling 228 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 38\n",
      "n_resources: 492\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 13\n",
      "n_resources: 1476\n",
      "Fitting 2 folds for each of 13 candidates, totalling 26 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 5\n",
      "n_resources: 4428\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 2\n",
      "n_resources: 13284\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "0.8785268929407755\n",
      "{'lasso__alpha': 0.060000000000000005, 'pca__n_components': 25}\n",
      "0.9499696323840465\n"
     ]
    }
   ],
   "source": [
    "lasso_cv = rate_regressor(X_train, y_train, X_test, y_test, lasso, lasso_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 8\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 8\n",
      "min_resources_: 18\n",
      "max_resources_: 39998\n",
      "aggressive_elimination: True\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 3060\n",
      "n_resources: 18\n",
      "Fitting 2 folds for each of 3060 candidates, totalling 6120 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 1020\n",
      "n_resources: 54\n",
      "Fitting 2 folds for each of 1020 candidates, totalling 2040 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 340\n",
      "n_resources: 162\n",
      "Fitting 2 folds for each of 340 candidates, totalling 680 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 114\n",
      "n_resources: 486\n",
      "Fitting 2 folds for each of 114 candidates, totalling 228 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 38\n",
      "n_resources: 1458\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 13\n",
      "n_resources: 4374\n",
      "Fitting 2 folds for each of 13 candidates, totalling 26 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 5\n",
      "n_resources: 13122\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "----------\n",
      "iter: 7\n",
      "n_candidates: 2\n",
      "n_resources: 39366\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "-0.004464279862749665\n",
      "{'pca__n_components': 28, 'svr__alpha': 0.050100000000000006, 'svr__loss': 'epsilon_insensitive', 'svr__max_iter': 10000, 'svr__penalty': 'l2'}\n",
      "-154970242.97898936\n"
     ]
    }
   ],
   "source": [
    "svr_cv = rate_regressor(X_train, y_train, X_test, y_test, svr, svr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 7\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 7\n",
      "min_resources_: 54\n",
      "max_resources_: 39998\n",
      "aggressive_elimination: True\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1938\n",
      "n_resources: 54\n",
      "Fitting 2 folds for each of 1938 candidates, totalling 3876 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 646\n",
      "n_resources: 162\n",
      "Fitting 2 folds for each of 646 candidates, totalling 1292 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 216\n",
      "n_resources: 486\n",
      "Fitting 2 folds for each of 216 candidates, totalling 432 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 72\n",
      "n_resources: 1458\n",
      "Fitting 2 folds for each of 72 candidates, totalling 144 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 24\n",
      "n_resources: 4374\n",
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 8\n",
      "n_resources: 13122\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 3\n",
      "n_resources: 39366\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "0.652238697379432\n",
      "{'pca__n_components': 28, 'rf__criterion': 'mse', 'rf__max_features': 'auto', 'rf__n_estimators': 30}\n",
      "0.2824917784932184\n"
     ]
    }
   ],
   "source": [
    "rf_cv = rate_regressor(X_train, y_train, X_test, y_test, rf, rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5109.67475816398"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(lasso_cv.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500479.9367198438"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.398289\n",
       "1      0.640595\n",
       "2      0.853540\n",
       "3      0.883260\n",
       "4      0.914458\n",
       "         ...   \n",
       "507    0.947661\n",
       "508    0.947619\n",
       "509    0.947678\n",
       "510    0.878488\n",
       "511    0.878527\n",
       "Name: mean_test_score, Length: 512, dtype: float64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lasso_cv.cv_results_).mean_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobadiah2",
   "language": "python",
   "name": "jobadiah2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
